{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fc06e35-34ca-494f-b2f5-9bd5acb0d884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn.utils.prune as prune\n",
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a453c95-071e-4a48-b18d-9fd2defcd271",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_sets_path = '/mnt/data/DatasetsML/CV/VOC_2012/VOC2012/ImageSets/Main/'\n",
    "train_path = os.path.join(image_sets_path, 'train.txt')\n",
    "val_path = os.path.join(image_sets_path, 'val.txt')\n",
    "\n",
    "images_path = '/mnt/data/DatasetsML/CV/VOC_2012/VOC2012/JPEGImages/'\n",
    "annnots_path = '/mnt/data/DatasetsML/CV/VOC_2012/VOC2012/Annotations/'\n",
    "\n",
    "train_images = utils.read_set(train_path)\n",
    "val_images = utils.read_set(val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ef928ad-b570-42d6-b107-1177156ce69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n",
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6bcf64c-ec5a-4407-827d-4db322ade135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 158.404 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model size: {utils.model_size(model):.3f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349b3b7b-57fe-415c-8fd6-6de50f2e0173",
   "metadata": {},
   "source": [
    "# Random Unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f323bd55-273b-43f6-8b9b-411bec4c1041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_rndm_unstr = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "900803c2-56c2-46a3-9aa9-a04481ee5253",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in model_rndm_unstr.named_modules():\n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        module = prune.random_unstructured(\n",
    "            module, name='weight', amount=0.05\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fedc926f-3fd2-4537-b8d8-667506b6f26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 158.404 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model size: {utils.model_size(model_rndm_unstr):.3f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8e2d7c8-20b6-4551-8bdc-47047f4d8bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1afe56b6d1b84efc860cc0bd073a600e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5823 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rndm_unstr_map, rndm_unstr_sec_per_frame = utils.evaluate_over_voc(\n",
    "    images_path=images_path,\n",
    "    annots_path=annnots_path,\n",
    "    val_images=val_images,\n",
    "    model=model_rndm_unstr,\n",
    "    proc=processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a402edd-09bf-4e91-9138-c2aa3e3f9f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'map': tensor(0.3023),\n",
       " 'map_50': tensor(0.4269),\n",
       " 'map_75': tensor(0.3252),\n",
       " 'map_small': tensor(0.0889),\n",
       " 'map_medium': tensor(0.2287),\n",
       " 'map_large': tensor(0.3514),\n",
       " 'mar_1': tensor(0.2754),\n",
       " 'mar_10': tensor(0.3533),\n",
       " 'mar_100': tensor(0.3543),\n",
       " 'mar_small': tensor(0.1085),\n",
       " 'mar_medium': tensor(0.2710),\n",
       " 'mar_large': tensor(0.3984),\n",
       " 'map_per_class': tensor(-1.),\n",
       " 'mar_100_per_class': tensor(-1.),\n",
       " 'classes': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19], dtype=torch.int32)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rndm_unstr_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc5db38c-38de-455c-8558-a9a37ab58385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.087"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rndm_unstr_sec_per_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548eac9e-b824-4711-a0fd-3dd1da4c8d90",
   "metadata": {},
   "source": [
    "# L1 Unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d71f2c4-767d-463f-a5d1-9948402462b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_l1_unstr = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74364b0c-2096-4657-b6a6-237f4aded453",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in model_l1_unstr.named_modules():\n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        prune.l1_unstructured(module, name='weight', amount=0.05)\n",
    "    elif isinstance(module, torch.nn.Linear):\n",
    "        prune.l1_unstructured(module, name='weight', amount=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97bf137b-f7a0-4d2a-b74c-bc880e6ffc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 158.404 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model size: {utils.model_size(model_l1_unstr):.3f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4482fa9c-33ca-439d-8712-3677354693f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f44a26e5301d44df89fd2a0ddc960bd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5823 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rndm_l1_map, rndm_l1_sec_per_frame = utils.evaluate_over_voc(\n",
    "    images_path=images_path,\n",
    "    annots_path=annnots_path,\n",
    "    val_images=val_images,\n",
    "    model=model_l1_unstr,\n",
    "    proc=processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8634eead-f966-4fbe-85f3-379a6ca51ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'map': tensor(0.5607),\n",
       " 'map_50': tensor(0.7275),\n",
       " 'map_75': tensor(0.6069),\n",
       " 'map_small': tensor(0.1946),\n",
       " 'map_medium': tensor(0.4117),\n",
       " 'map_large': tensor(0.6605),\n",
       " 'mar_1': tensor(0.4638),\n",
       " 'mar_10': tensor(0.6239),\n",
       " 'mar_100': tensor(0.6262),\n",
       " 'mar_small': tensor(0.2536),\n",
       " 'mar_medium': tensor(0.4804),\n",
       " 'mar_large': tensor(0.7113),\n",
       " 'map_per_class': tensor(-1.),\n",
       " 'mar_100_per_class': tensor(-1.),\n",
       " 'classes': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19], dtype=torch.int32)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rndm_l1_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fef42a94-090a-4b85-8ebe-bac505116b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.089"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rndm_l1_sec_per_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6233f79-ee39-451d-a731-9815ce0c4e5e",
   "metadata": {},
   "source": [
    "# Ln Unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13a665ef-c694-4c32-afcd-1b8b15a64820",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_ln_unstr = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40903449-37d1-4e28-8e02-dde6708764dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in model_ln_unstr.named_modules():\n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        prune.ln_structured(module, name='weight', amount=0.05, n=2, dim=1)\n",
    "    elif isinstance(module, torch.nn.Linear):\n",
    "        prune.ln_structured(module, name='weight', amount=0.05, n=2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89e6dcd3-e23c-4cc5-bb64-1db7808b041e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 158.404 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model size: {utils.model_size(model_ln_unstr):.3f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "747b34f6-67b8-4c20-b04f-9f38b7ff444e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13359c62f7dd4907b4a39ed27e9d0088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5823 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rndm_ln_map, rndm_ln_sec_per_frame = utils.evaluate_over_voc(\n",
    "    images_path=images_path,\n",
    "    annots_path=annnots_path,\n",
    "    val_images=val_images,\n",
    "    model=model_ln_unstr,\n",
    "    proc=processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb12cabe-f085-418b-b215-6b350179d6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'map': tensor(0.1291),\n",
       " 'map_50': tensor(0.2739),\n",
       " 'map_75': tensor(0.1131),\n",
       " 'map_small': tensor(0.0018),\n",
       " 'map_medium': tensor(0.0267),\n",
       " 'map_large': tensor(0.1943),\n",
       " 'mar_1': tensor(0.1955),\n",
       " 'mar_10': tensor(0.2822),\n",
       " 'mar_100': tensor(0.3188),\n",
       " 'mar_small': tensor(0.0166),\n",
       " 'mar_medium': tensor(0.1179),\n",
       " 'mar_large': tensor(0.4290),\n",
       " 'map_per_class': tensor(-1.),\n",
       " 'mar_100_per_class': tensor(-1.),\n",
       " 'classes': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19], dtype=torch.int32)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rndm_ln_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09611bd1-758e-4feb-8455-f82c996b70a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rndm_ln_sec_per_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515cd960-3971-42f7-a57d-89f2edecf316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
